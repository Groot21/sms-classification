{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86333985",
   "metadata": {},
   "source": [
    "# Results and Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7236545a",
   "metadata": {},
   "source": [
    "## Findings on the Dataset\n",
    "\n",
    "- Imbalanced dataset, majority of legitimate sms\n",
    "\n",
    "- Focus on minimizing misclassified ham messages (MH: percentage of misclassified ham messages)\n",
    "\n",
    "\n",
    "### TL;DR: The winner is the classical approach!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddad5bc",
   "metadata": {},
   "source": [
    "## Classical Approach\n",
    "\n",
    "Based on TF-IDF\n",
    "\n",
    "### Hyperparameter Study \n",
    "- Use \"classical\" ml models for binary classification: Logistic Regression, Naives Bayes, SVM, Decision Tree.\n",
    "- Best Model found for SVM. Hyperparameter configuration: `SVC(C=1., kernel='linear')`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cb5964",
   "metadata": {},
   "source": [
    "## LLM with Zero-Shot Learning\n",
    "\n",
    "- Model: \"facebook/bart-large-mnli\"\n",
    "\n",
    "### \"Hyperparameter Study\"\n",
    "- Investigated differnet hypotheses. Best one: \"This sms text belongs to the {} category.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cd9833",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "\n",
    "| Metric   | Classical Approach (SVM) | LLM Approach |\n",
    "| -------- | ------- | ------- |\n",
    "| *Training Time*  | seconds   | 0 (due to zero-shot) |\n",
    "| *Inference Time* | seconds   | multiple minutes     |\n",
    "\n",
    "### Metrics SVM\n",
    "|             | precision  |  recall | f1-score  | support|\n",
    "| -------- | ------- | ------- | -------- | ------- |\n",
    "|           0  |     0.98   |   1.00     | 0.99 |      894|\n",
    "|           1  |     0.97   |   0.89    |  0.93  |     140|\n",
    "|    accuracy  |            |          |   0.98   |   1034|\n",
    "|   macro avg  |     0.98   |   0.94  |    0.96    |  1034|\n",
    "|weighted avg  |     0.98    |  0.98 |     0.98     | 1034|\n",
    "\n",
    "Confusion Matrix:  \n",
    "| | Ham| Spam |\n",
    "| -------- | ------- | ------- | \n",
    "| Ham  | 890 | 4 |\n",
    "| Spam | 15  | 125 |\n",
    "\n",
    "\n",
    "### Metrics LLM\n",
    "|             | precision  |  recall | f1-score  | support|\n",
    "| -------- | ------- | ------- | -------- | ------- |\n",
    "|           0     |  0.87   |   0.36    |  0.51      | 894|\n",
    "|           1    |   0.14   |   0.64    |  0.22     |  140|\n",
    "|    accuracy   |           |        |     0.40    |  1034|\n",
    "|   macro avg    |   0.50  |    0.50  |    0.37   |   1034|\n",
    "|weighted avg     |  0.77 |     0.40   |   0.47  |    1034|\n",
    "\n",
    "Confusion Matrix:  \n",
    "| | Ham| Spam |\n",
    "| -------- | ------- | ------- | \n",
    "| Ham  | 322 | 572 |\n",
    "| Spam | 50  | 90 |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
